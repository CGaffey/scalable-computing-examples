{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries we need\n",
    "import os\n",
    "\n",
    "import parsl\n",
    "from parsl import python_app\n",
    "from parsl.config import Config\n",
    "from parsl.channels import LocalChannel\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "from parsl.providers import LocalProvider\n",
    "\n",
    "# helper functions\n",
    "from grouputils import initialize_stager\n",
    "from grouputils import plot_tiles\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The first step in our workflow is to \"stage\" our data. Staging the data encompasses the following pre-processing tasks:\n",
    "\n",
    "- simplify the polygons \n",
    "- set an input CRS if one is missing\n",
    "- reproject the data when required\n",
    "- add additional properties to each polygon, including: the centroid x and y\n",
    "  coordinates, the area, a unique ID, and the name of the file that the\n",
    "  polygon originated from\n",
    "- break each input file into [standardized tiles](https://docs.opengeospatial.org/is/17-083r2/17-083r2.html)\n",
    "- save them to disk, following a file hierarchy and naming format for x, y, and z coordinates of the tiles\n",
    "\n",
    "Here is a diagram showing what the most important step, the last one, looks like.\n",
    "\n",
    "![](https://raw.githubusercontent.com/PermafrostDiscoveryGateway/viz-staging/develop/docs/images/staging_tldr.png)\n",
    "\n",
    "We will use some methods from the `pdgstaging` library to stage our tiles. The first step, is to initalize the `TileStager`. The `TileStager` is a class with a method `stage`, which works on a single vector file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initalize the stager\n",
    "\n",
    "Fist we need to use the `initialize_stager` function to instantiate the `TileStager` object. The only argument to this function is `dir_input`, the directory of input data.\n",
    "\n",
    "Input vector files are located **in `/home/shares/example-pdg-data`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the initialize_stager function with the filepath for the input data\n",
    "# save the result to a variable called iwp_stager\n",
    "iwp_stager = initialize_stager(\"/home/shares/example-pdg-data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `iwp_stager` object works as a tool that communicates between the configuration settings and the staging function. The stager tells the staging function:\n",
    "- where to pull the input files from\n",
    "- where to write the staged tiles\n",
    "- the coordinate reference system to use\n",
    "- whether the input data should be deduplicated, etc.\n",
    "\n",
    "Next let's use it to get a list of files to stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_stage = iwp_stager.tiles.get_filenames_from_dir('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files_to_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split the input files into batches\n",
    "# def batch(all_files, batch_size):\n",
    "#     return [all_files[i:i + batch_size] for i in range(0, len(all_files), batch_size)]\n",
    "\n",
    "# file_batches = batch(files_to_stage, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(file_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage one file\n",
    "\n",
    "Here is an example of how to run the stager on one file. We use the `stage` method on the `iwp_stager` object, with a path to a file as the argument to the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_file = files_to_stage[0]\n",
    "\n",
    "iwp_stager.stage(example_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on how long staging one file took, estimate how long that would take to stage all the input files that we have in this example, serially. How long would it take if we had 100 files? 1000?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate computation time\n",
    "100*66 # answer in seconds\n",
    "(100*66)/60 # answer in minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these example data, the amount of time it takes is not super high. But as the number of files gets bigger, things get out of hand quickly. Luckily for us, this problem is pleasingly parallel. The staging of each file is completely independent of the others. So, let's set this up as a `parsl` workflow using the skills we learned in Section 4. \n",
    "\n",
    "Just to get a sense of what happened, let's plot the result of our test staging effort using a `plot_tiles` helper we wrote for this activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tiles(iwp_stager)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's remove the files we just created (including the staging summary csv file that's generated with the staged files) to prepare to run this over all of the files.\n",
    "\n",
    "If we don't do this, polygons will get appended to the staged files which will result in duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f'rm -rf {iwp_stager.config.get(\"dir_staged\")}')\n",
    "os.system(f'rm {iwp_stager.config.get(\"filename_staging_summary\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Staging in parallel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set up the configuration for `parsl` using `config`, and a `HighThroughputExecutor`. For the executor, set the `max_workers` to 32, and set the `max_blocks` to 1. This will spread our work over 32 processes on the server. Make sure you pass the bash command you use to invoke your virtual environment to the `worker_init` argument as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPLATE FOR PARSL CONFIG:\n",
    "# htex_config = config(\n",
    "#   executors=[\n",
    "#       HighThroughputExecutor(\n",
    "#           ..., \n",
    "#           provider = LocalProvider(...)\n",
    "#       )\n",
    "#   ]\n",
    "# )\n",
    "\n",
    "activate_env = 'workon scomp2023-03-20'\n",
    "htex_local = Config(\n",
    "    executors=[\n",
    "        HighThroughputExecutor(\n",
    "            max_workers=32, # can reduce this when reduce numb of input files\n",
    "            provider=LocalProvider(\n",
    "                worker_init=activate_env,\n",
    "                max_blocks = 1 # default\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "parsl.clear()\n",
    "parsl.load(htex_local)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set up your Parsl app to run the `stage` method in parallel. You'll need to pass 2 arguments to the app function:\n",
    "1. The path to the input file.\n",
    "2. The `TileStager` instance we created earlier.\n",
    "\n",
    "Note how the function returns the input path. This will give us something to interate over, since the `stage` method returns `None` (and writes files!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorators seem to be ignored as the first line of a cell, so print something first\n",
    "#print(\"Stage in parallel\")\n",
    "\n",
    "# Make a Parsl app that uses the stage method\n",
    "# function arguments: path, stager\n",
    "\n",
    "@python_app\n",
    "def stage_file(path, stager):\n",
    "    stager.stage(path)\n",
    "    return path\n",
    "\n",
    "# @python_app\n",
    "# def stage_file(batch, stager):\n",
    "#     for path in batch:\n",
    "#         stager.stage(path)\n",
    "#     return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, execute the app in parallel over all of the `files_to_stage`. In this solution, we use a simple loop to run our parsl app, and then list comprehension to retrieve the result from our futures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_app_futures = []\n",
    "# for batch in file_batches:\n",
    "#     app_future = stage_file(batch, iwp_stager)\n",
    "#     all_app_futures.append(app_future)\n",
    "\n",
    "# [app_future.result() for app_future in all_app_futures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the app using app.futures\n",
    "all_app_futures = []\n",
    "for path in files_to_stage:\n",
    "    app_future = stage_file(path, iwp_stager)\n",
    "    all_app_futures.append(app_future)\n",
    "\n",
    "# By getting the `result()` of each app future, this block won't continue to \n",
    "# the print statement until all the files are staged.\n",
    "[app_future.result() for app_future in all_app_futures] \n",
    "\n",
    "# shutdown and clear the parsl executor\n",
    "htex_local.executors[0].shutdown()\n",
    "parsl.clear() # took 25 min to produce 2249 gpkg files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Syntax\n",
    "\n",
    "Here is a second solution, similar to the syntax in the Course Materials section [\"parallel processing with parsl\"](https://learning.nceas.ucsb.edu/2023-03-arctic/sections/parallel-programming.html#parallel-processing-with-parsl).\n",
    "\n",
    "This approach wraps the loop and futures blocks into their own functions. Either solution will work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #os.system(f'rm -rf {iwp_stager.config.get(\"dir_staged\")}')\n",
    "# #os.system(f'rm {iwp_stager.config.get(\"filename_staging_summary\")}')\n",
    "\n",
    "# activate_env = 'workon scomp2023-03-20'\n",
    "# htex_local = Config(\n",
    "#     executors=[\n",
    "#         HighThroughputExecutor(\n",
    "#             max_workers=32,\n",
    "#             provider=LocalProvider(\n",
    "#                 worker_init=activate_env\n",
    "#             )\n",
    "#         )\n",
    "#     ],\n",
    "# )\n",
    "# parsl.clear()\n",
    "# parsl.load(htex_local)\n",
    "\n",
    "# @python_app\n",
    "# def stage_files(files):\n",
    "#     all_results = []\n",
    "#     for file in files:\n",
    "#         result = stage_file(file, iwp_stager)\n",
    "#         all_results.append(result)\n",
    "#     return(all_results)\n",
    "\n",
    "# def wait_for_futures(files):\n",
    "#     all_results = stage_files(files)\n",
    "#     done = [app_future.result() for app_future in all_results]\n",
    "#     print(done)\n",
    "\n",
    "# wait_for_futures(files_to_stage) # takes 5-11 min when run before SCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # don't forget to shutdown and clear your executor\n",
    "# htex_local.executors[0].shutdown()\n",
    "# parsl.clear()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check out the `plot_tiles` result again (which will only plot the first 45 of our tiled files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tiles(iwp_stager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "This process took the original 35 files, ranging in size from 20MB to 500MB (6 GB total), and tiled them into arond 2200 files, and if you set up your executor like we described, it should have taken around 15 minutes. \n",
    "\n",
    "Discuss in your groups whether you suspect this process is CPU bound, I/O bound, memory bound, or network bound. How would you figure it out for sure? Why would you want to know?\n",
    "\n",
    "### Answer\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('scomp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0030ed2ed4c0609037967981d5426019e14a913516344490dbc8ffbbe92f86b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
